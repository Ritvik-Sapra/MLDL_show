{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using CNN\n",
    "\n",
    "Using CNN, we can add **Convolution layers and Maxpooling**, which increases the accuracy of our model dramatically. The code written without CNN had highest accuracy of 65%. Whereas, using CNN highest accuracy obtained was **89%**, which is very impressive!\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "The dataset contains images about different weather. The task is to classify an image to what **kind of weather** it is showing.\n",
    "\n",
    "The dataset is divided into three parts, Train, Test and Validate. \n",
    "\n",
    "Furthermore, it has four classes: **Cloudy, Rain, Shine and Sunrise**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required Libraries\n",
    "\n",
    "We are working with TensorFlow and Keras with TensorFlow as backend. Below we import all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the image width and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 28,28\n",
    "\n",
    "#defining the data directories\n",
    "train_data_dir= 'Data/Train'\n",
    "validation_data_dir= 'Data/Validation'\n",
    "n_training_sample= 400\n",
    "n_validation_sample= 100\n",
    "epochs=20\n",
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and defining the model\n",
    "\n",
    "We add hidden layers in our model along with Convolution layers and Maxpooling. Here, we are implementing 2d Convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(500, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.relu), \n",
    "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(4, activation=tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 606 images belonging to 4 classes.\n",
      "Found 307 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We now run and train our model with 50 epochs and 10 batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-29de0551918b>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021B65503708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000021B65503708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.9906 - accuracy: 0.5650WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021B6562CC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000021B6562CC18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "40/40 [==============================] - 27s 673ms/step - loss: 0.9906 - accuracy: 0.5650 - val_loss: 0.7201 - val_accuracy: 0.6400\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 25s 635ms/step - loss: 0.7573 - accuracy: 0.6111 - val_loss: 0.8129 - val_accuracy: 0.5800\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 13s 329ms/step - loss: 0.7563 - accuracy: 0.6650 - val_loss: 0.5612 - val_accuracy: 0.6907\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 0.6311 - accuracy: 0.7197 - val_loss: 0.6291 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 9s 234ms/step - loss: 0.6002 - accuracy: 0.7197 - val_loss: 0.5834 - val_accuracy: 0.7900\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.5858 - accuracy: 0.7500 - val_loss: 0.4250 - val_accuracy: 0.7732\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 0.4755 - accuracy: 0.7929 - val_loss: 0.4519 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.4913 - accuracy: 0.7955 - val_loss: 0.3824 - val_accuracy: 0.8900\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.4407 - accuracy: 0.8325 - val_loss: 0.2847 - val_accuracy: 0.9485\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 12s 291ms/step - loss: 0.4789 - accuracy: 0.7778 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 9s 229ms/step - loss: 0.4128 - accuracy: 0.8056 - val_loss: 0.4947 - val_accuracy: 0.8600\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 11s 271ms/step - loss: 0.3998 - accuracy: 0.8650 - val_loss: 0.3250 - val_accuracy: 0.8866\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 0.3856 - accuracy: 0.8561 - val_loss: 0.2502 - val_accuracy: 0.9300\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 10s 251ms/step - loss: 0.3065 - accuracy: 0.8838 - val_loss: 0.6179 - val_accuracy: 0.7800\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 10s 253ms/step - loss: 0.3303 - accuracy: 0.8825 - val_loss: 0.8451 - val_accuracy: 0.6907\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 13s 327ms/step - loss: 0.3513 - accuracy: 0.8712 - val_loss: 0.5137 - val_accuracy: 0.8900\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 11s 273ms/step - loss: 0.3190 - accuracy: 0.8712 - val_loss: 0.5199 - val_accuracy: 0.8557\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 0.2935 - accuracy: 0.8775 - val_loss: 0.4890 - val_accuracy: 0.8600\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 0.3328 - accuracy: 0.8990 - val_loss: 0.7631 - val_accuracy: 0.8300\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 0.2843 - accuracy: 0.8838 - val_loss: 0.3225 - val_accuracy: 0.8557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21b65148588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_training_sample // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_sample // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "\n",
    "As explained at the starting of this project, there are **four classes** in this dataset. The **result** shown corresponding to the four classes: 1, 2, 3 & 4, each element representing the class. \n",
    "\n",
    "For e.g. if the fourth position shows 1, that means model is predicting that the image belongs to the 4 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "pred= image.load_img('Data/Test/sunrise345.jpg', target_size=(28,28))\n",
    "pred=image.img_to_array(pred)\n",
    "pred= np.expand_dims(pred, axis=0)\n",
    "result= model.predict(pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We implemented CNN in the Image classifier program and observed how the accuracy is improved through a considerable factor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
