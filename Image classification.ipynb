{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using NN\n",
    "\n",
    "This is a simple project showcasing how we can build a model to classify images through **Neural Networks**. \n",
    "\n",
    "The highest accuracy achieved through this model is 68%, which is pretty good for a NN.\n",
    "*Note: There is a seperate project depicting CNN on the same dataset and how the accuracy is improved.*\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "The dataset contains images about different weather. The task is to classify an image to what kind of weather it is showing.\n",
    "\n",
    "The dataset is divided into three parts, Train, Test and Validate. \n",
    "\n",
    "Furthermore, it has four classes: Cloudy, Rain, Shine and Sunrise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the necessary libraries\n",
    "\n",
    "We are working here with TensorFlow and Keras, with TensorFlow as backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the image width and heght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = \"Data/Train\"\n",
    "validation_data_dir = \"Data/Validation\"\n",
    "n_training_sample= 100\n",
    "n_validation_sample= 80\n",
    "epochs=50\n",
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([tf.keras.layers.Flatten(), \n",
    "                      tf.keras.layers.Dense(500, activation=tf.nn.sigmoid), \n",
    "                                    kr.layers.Dense(256, activation=tf.nn.relu), \n",
    "                                    kr.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    kr.layers.Dense(4, activation=tf.nn.sigmoid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running and training the model\n",
    "\n",
    "Training our model with 50 epochs and 10 as the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 606 images belonging to 4 classes.\n",
      "Found 307 images belonging to 4 classes.\n",
      "WARNING:tensorflow:From <ipython-input-6-ab60d993da28>:28: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025B4AD01DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025B4AD01DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/10 [==============================] - ETA: 0s - loss: 1.3897 - accuracy: 0.3400WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025B4AFAAEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025B4AFAAEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.3897 - accuracy: 0.3400 - val_loss: 1.3469 - val_accuracy: 0.2250\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 6s 635ms/step - loss: 1.3282 - accuracy: 0.3800 - val_loss: 1.2227 - val_accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 8s 846ms/step - loss: 1.3492 - accuracy: 0.3100 - val_loss: 1.3549 - val_accuracy: 0.3375\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 6s 634ms/step - loss: 1.3463 - accuracy: 0.4400 - val_loss: 1.3242 - val_accuracy: 0.5325\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 5s 495ms/step - loss: 1.3643 - accuracy: 0.4700 - val_loss: 1.3530 - val_accuracy: 0.5375\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 10s 997ms/step - loss: 1.3621 - accuracy: 0.4500 - val_loss: 1.3564 - val_accuracy: 0.4875\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 4s 404ms/step - loss: 1.3472 - accuracy: 0.3750 - val_loss: 1.3323 - val_accuracy: 0.2468\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 1.2904 - accuracy: 0.3400 - val_loss: 1.2704 - val_accuracy: 0.3250\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 5s 537ms/step - loss: 1.2618 - accuracy: 0.3500 - val_loss: 1.2764 - val_accuracy: 0.3375\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 1.2491 - accuracy: 0.3500 - val_loss: 1.2776 - val_accuracy: 0.3000\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 5s 497ms/step - loss: 1.2939 - accuracy: 0.3300 - val_loss: 1.2562 - val_accuracy: 0.2468\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 4s 392ms/step - loss: 1.2131 - accuracy: 0.3900 - val_loss: 1.3052 - val_accuracy: 0.3000\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 5s 487ms/step - loss: 1.1997 - accuracy: 0.4583 - val_loss: 1.0928 - val_accuracy: 0.4750\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 4s 443ms/step - loss: 1.0898 - accuracy: 0.5300 - val_loss: 1.2767 - val_accuracy: 0.3636\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 5s 456ms/step - loss: 1.0745 - accuracy: 0.6100 - val_loss: 1.3280 - val_accuracy: 0.3875\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 4s 393ms/step - loss: 1.1381 - accuracy: 0.5100 - val_loss: 0.9681 - val_accuracy: 0.4500\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 5s 484ms/step - loss: 1.1123 - accuracy: 0.3900 - val_loss: 1.0543 - val_accuracy: 0.4125\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 5s 462ms/step - loss: 1.1023 - accuracy: 0.5400 - val_loss: 1.1398 - val_accuracy: 0.4416\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 4s 432ms/step - loss: 1.0631 - accuracy: 0.4688 - val_loss: 0.9634 - val_accuracy: 0.4875\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.9432 - accuracy: 0.5900 - val_loss: 0.9919 - val_accuracy: 0.4375\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 5s 460ms/step - loss: 1.1712 - accuracy: 0.4800 - val_loss: 0.9628 - val_accuracy: 0.5065\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 5s 456ms/step - loss: 1.1453 - accuracy: 0.4700 - val_loss: 0.8458 - val_accuracy: 0.6375\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.9827 - accuracy: 0.5000 - val_loss: 0.9499 - val_accuracy: 0.4625\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.8377 - accuracy: 0.6200 - val_loss: 0.9651 - val_accuracy: 0.4375\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 1.0828 - accuracy: 0.4896 - val_loss: 1.3083 - val_accuracy: 0.4156\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 4s 424ms/step - loss: 1.2207 - accuracy: 0.4100 - val_loss: 1.1468 - val_accuracy: 0.4375\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.9387 - accuracy: 0.5300 - val_loss: 0.8754 - val_accuracy: 0.5250\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 5s 486ms/step - loss: 0.8896 - accuracy: 0.6000 - val_loss: 0.8469 - val_accuracy: 0.5714\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 5s 484ms/step - loss: 1.0213 - accuracy: 0.4800 - val_loss: 0.7810 - val_accuracy: 0.5875\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.8433 - accuracy: 0.6200 - val_loss: 0.9664 - val_accuracy: 0.4250\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 5s 452ms/step - loss: 0.8439 - accuracy: 0.5729 - val_loss: 0.8065 - val_accuracy: 0.6000\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 4s 444ms/step - loss: 0.9914 - accuracy: 0.5500 - val_loss: 0.8864 - val_accuracy: 0.5125\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 5s 450ms/step - loss: 0.8359 - accuracy: 0.6800 - val_loss: 0.8794 - val_accuracy: 0.5125\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 4s 449ms/step - loss: 0.9827 - accuracy: 0.5400 - val_loss: 0.8866 - val_accuracy: 0.5625\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 6s 552ms/step - loss: 0.8335 - accuracy: 0.6700 - val_loss: 0.9175 - val_accuracy: 0.5195\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 5s 507ms/step - loss: 0.8796 - accuracy: 0.6000 - val_loss: 0.9186 - val_accuracy: 0.5125\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 5s 474ms/step - loss: 0.9067 - accuracy: 0.5000 - val_loss: 0.9982 - val_accuracy: 0.4750\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 4s 448ms/step - loss: 0.8567 - accuracy: 0.5700 - val_loss: 0.9092 - val_accuracy: 0.5065\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 5s 480ms/step - loss: 0.8970 - accuracy: 0.5900 - val_loss: 0.9688 - val_accuracy: 0.5625\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 1.0530 - accuracy: 0.4500 - val_loss: 1.1307 - val_accuracy: 0.4625\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 0.9635 - accuracy: 0.5900 - val_loss: 1.0062 - val_accuracy: 0.5125\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.9603 - accuracy: 0.5400 - val_loss: 1.0720 - val_accuracy: 0.3766\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 5s 516ms/step - loss: 1.1110 - accuracy: 0.4583 - val_loss: 0.8528 - val_accuracy: 0.5125\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 1.1777 - accuracy: 0.4800 - val_loss: 1.0528 - val_accuracy: 0.4500\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 1.0724 - accuracy: 0.4800 - val_loss: 0.9803 - val_accuracy: 0.5065\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 5s 502ms/step - loss: 0.9727 - accuracy: 0.5400 - val_loss: 0.9381 - val_accuracy: 0.6250\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.8347 - accuracy: 0.6600 - val_loss: 0.7950 - val_accuracy: 0.5375\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 5s 452ms/step - loss: 1.0231 - accuracy: 0.5800 - val_loss: 0.8641 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 5s 546ms/step - loss: 0.9559 - accuracy: 0.5208 - val_loss: 0.8284 - val_accuracy: 0.5844\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 6s 600ms/step - loss: 1.0362 - accuracy: 0.4700 - val_loss: 0.9668 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25b4ad24048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=n_training_sample // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_sample // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting\n",
    "\n",
    "As explained at the starting of this project, there are **four classes** in this dataset. The **result** shown corresponding to the four classes: 1, 2, 3 & 4, each element representing the class. \n",
    "\n",
    "For e.g. if the fourth position shows 1, that means model is predicting that the image belongs to the 4 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4853421  0.36998028 0.14843236 0.28983533]]\n",
      "Class:  0\n"
     ]
    }
   ],
   "source": [
    "pred= image.load_img('data/test/cloudy267.jpg', target_size=(150,150))\n",
    "pred=image.img_to_array(pred)\n",
    "pred= np.expand_dims(pred, axis=0)\n",
    "result= model.predict(pred)\n",
    "print(result)\n",
    "\n",
    "\n",
    "img_class = model.predict_classes(pred)\n",
    "\n",
    "classname = img_class[0]\n",
    "print(\"Class: \",classname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counclusion\n",
    "\n",
    "The model correctly predicted the class of the image provided. However, the accuracy of the model can be increased.Thus, we apply CNN and check the accuracy of predicting again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
